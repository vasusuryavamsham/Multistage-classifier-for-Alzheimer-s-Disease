{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from multiprocessing import Pool  # For parallel processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing columns: ['directory.id', 'Subject', 'RID', 'Image.Data.ID', 'Modality', 'Visit', 'Acq.Date', 'EXAMDATE', 'Dx Codes for Submission']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vasu5\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "  # y = data[\"DX.bl\"]\n",
    "  # Drop unnecessary features (e.g., index, directory.id)\n",
    "  # remove_columns = list(data.columns)[0:9]\n",
    "  remove_columns = ['directory.id', 'Subject', 'RID', 'Image.Data.ID', 'Modality', 'Visit', 'Acq.Date', 'EXAMDATE', 'Dx Codes for Submission']\n",
    "  print('Removing columns:', remove_columns)\n",
    "  data = data.drop(remove_columns, axis=1)\n",
    "\n",
    "  # Handle missing values\n",
    "  imputer = SimpleImputer(strategy=\"mean\")\n",
    "  data[[\"AGE\", \"PTEDUCAT\", \"MMSE\"]] = imputer.fit_transform(data[[\"AGE\", \"PTEDUCAT\", \"MMSE\"]])\n",
    "\n",
    "  \n",
    "\n",
    "  # One-Hot Encode categorical features\n",
    "  categorical_features = [\"PTGENDER\", \"PTETHCAT\", \"PTRACCAT\", \"APOE Genotype\"]  # Add APOE Genotype\n",
    "  encoder = OneHotEncoder(sparse=False)\n",
    "  data = pd.concat([data, pd.DataFrame(encoder.fit_transform(data[categorical_features]))], axis=1)\n",
    "  data.drop(categorical_features, axis=1, inplace=True)\n",
    "\n",
    "  # Feature scaling (consider for specific models)\n",
    "  scaler = StandardScaler()\n",
    "  data[[\"AGE\", \"MMSE\"]] = scaler.fit_transform(data[[\"AGE\", \"MMSE\"]])\n",
    "  \n",
    "  data = data.dropna(subset=['imputed_genotype'])\n",
    "\n",
    "  # Separate features (X) and target variable (y)\n",
    "  X = data.drop(\"DX.bl\", axis=1)\n",
    "  y = data[\"DX.bl\"]\n",
    "  \n",
    "  X.columns = X.columns.astype(str)\n",
    "\n",
    "  return X, y\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"data/ADNI_Training_Q3_APOE_CollectionADNI1Complete 1Yr 1.5T_July22.2014.csv\")\n",
    "\n",
    "# Preprocess data\n",
    "X, y = preprocess_data(data.copy())\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                 0\n",
       "PTEDUCAT            0\n",
       "APOE4               0\n",
       "MMSE                0\n",
       "imputed_genotype    0\n",
       "0                   0\n",
       "1                   0\n",
       "2                   0\n",
       "3                   0\n",
       "4                   0\n",
       "5                   0\n",
       "6                   0\n",
       "7                   0\n",
       "8                   0\n",
       "9                   0\n",
       "10                  0\n",
       "11                  0\n",
       "12                  0\n",
       "13                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data\n",
    "# Y = data['DX.bl']\n",
    "# # del data\n",
    "\n",
    "# remove_columns = list(X.columns)[0:9]\n",
    "# remove_columns.append('Dx Codes for Submission')\n",
    "# print('Removing columns:', remove_columns)\n",
    "\n",
    "# X = X.drop(remove_columns, axis=1)\n",
    "\n",
    "# features = list(X.columns)\n",
    "# X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['directory.id', 'Subject', 'RID', 'Image.Data.ID', 'Modality', 'Visit',\n",
      "       'Acq.Date', 'DX.bl', 'EXAMDATE', 'AGE', 'PTGENDER', 'PTEDUCAT',\n",
      "       'PTETHCAT', 'PTRACCAT', 'APOE4', 'MMSE', 'imputed_genotype',\n",
      "       'APOE Genotype', 'Dx Codes for Submission'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>imputed_genotype</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.917438</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.703157</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.147780</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031099</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.219929</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812315</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782750</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750117</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.189998</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.140725</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE  PTEDUCAT  APOE4      MMSE imputed_genotype    0    1    2    3  \\\n",
       "0  0.917438      18.0      1 -2.703157             True  0.0  1.0  0.0  1.0   \n",
       "1 -1.147780      10.0      0  0.031099            False  0.0  1.0  1.0  0.0   \n",
       "2 -0.219929      16.0      0  0.812315             True  0.0  1.0  0.0  1.0   \n",
       "3  0.782750      13.0      0 -0.750117             True  1.0  0.0  0.0  1.0   \n",
       "4 -0.189998      12.0      1 -1.140725             True  1.0  0.0  0.0  1.0   \n",
       "\n",
       "     4    5    6    7    8    9   10   11   12   13  \n",
       "0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.columns)\n",
    "X.head()\n",
    "# y.info()\n",
    "# y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage1_model(X_train, y_train):\n",
    "  # Define and train Random Forest model with hyperparameter tuning\n",
    "  param_grid = {\n",
    "      \"n_estimators\": [100, 200, 300],\n",
    "      \"max_depth\": [5, 10, 15]\n",
    "  }\n",
    "  model_stage1 = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "  model_stage1.fit(X_train, y_train)\n",
    "  best_model = model_stage1.best_estimator_\n",
    "  return best_model\n",
    "\n",
    "# Train Stage 1 model\n",
    "model_stage1 = train_stage1_model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LMCI'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stage1.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stage2(datapoint, model_lmc, model_ad):\n",
    "  # Predict probabilities for both LMCI and AD models\n",
    "  proba_lmc = model_lmc.predict_proba(datapoint.reshape(1, -1))[:, 1]\n",
    "  proba_ad = model_ad.predict_proba(datapoint.reshape(1, -1))[:, 1]\n",
    "  # Assign class based on higher probability\n",
    "  return \"LMCI\" if proba_lmc > proba_ad else \"AD\"\n",
    "\n",
    "def parallel_stage2_prediction(X_not_cn, model_lmc, model_ad):\n",
    "  # Use multiprocessing for parallel prediction\n",
    "  with Pool() as pool:\n",
    "    y_pred_stage2 = pool.starmap(predict_stage2, zip(X_not_cn, [model_lmc] * len(X_not_cn), [model_ad] * len(X_not_cn)))\n",
    "  return y_pred_stage2\n",
    "\n",
    "def train_stage2_models(X_train_not_cn, y_train_not_cn):\n",
    "  # Train separate models for LMCI and AD with hyperparameter tuning\n",
    "  param_grid_lmc = {\"kernel\": [\"linear\", \"rbf\"], \"C\": [0.1, 1, 10]}\n",
    "  param_grid_ad = {\"kernel\": [\"linear\", \"rbf\"], \"C\": [0.1, 1, 10]}\n",
    "  model_lmc = GridSearchCV(SVC(random_state=42), param_grid_lmc, cv=5)\n",
    "  model_ad = GridSearchCV(SVC(random_state=42), param_grid_ad, cv=5)\n",
    "  model_lmc.fit(X_train_not_cn, y_train_not_cn)\n",
    "  model_ad.fit(X_train_not_cn, y_train_not_cn)\n",
    "  best_model_lmc = model_lmc.best_estimator_\n",
    "  best_model_ad = model_ad.best_estimator_\n",
    "  return best_model_lmc, best_model_ad\n",
    "\n",
    "# Stage 2: Train LMCI and AD models (replace with your chosen models)\n",
    "model_lmc, model_ad = train_stage2_models(X_train[y_train != \"CN\"], y_train[y_train != \"CN\"])\n",
    "\n",
    "# Predict Stage 2 labels for Not CN data using parallel processing\n",
    "y_pred_stage2 = parallel_stage2_prediction(X_test[y_test != \"CN\"], model_lmc, model_ad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "  # Calculate accuracy, precision, recall, F1-score\n",
    "  accuracy = accuracy_score(y_true, y_pred)\n",
    "  report = classification_report(y_true, y_pred)\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "  print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Evaluate Stage 1 model\n",
    "evaluate_model(y_test, model_stage1.predict(X_test))\n",
    "\n",
    "# Evaluate Stage 2 model (considering only Not CN data from test set)\n",
    "evaluate_model(y_test[y_test != \"CN\"], y_pred_stage2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
